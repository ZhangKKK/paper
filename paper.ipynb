{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x3x256x256]\n",
      ", \n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.ImageFolder(    \n",
    "    root='test',    \n",
    "    transform=T.Compose([    \n",
    "            T.ToTensor(),    \n",
    "             \n",
    "        ])    \n",
    ")    \n",
    "\n",
    "dataloader1 = torch.utils.data.DataLoader(dataset, batch_size = 1)    \n",
    "iterator1 = iter(dataloader1)  \n",
    "for i in range(1):  \n",
    "    data = iterator1.next()\n",
    "    print data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Segmenter, self).__init__()\n",
    "        self.res_normal_1 = nn.Sequential(nn.Conv3d(4, 30, 3), \n",
    "                                             nn.Conv3d(30, 30, 3), \n",
    "                                             nn.Conv3d(30, 40, 3),\n",
    "                                             nn.Conv3d(40, 40, 3))\n",
    "        self.res_normal_2 = nn.Sequential(nn.Conv3d(40, 40, 3),\n",
    "                                             nn.Conv3d(40, 40, 3))\n",
    "        self.res_normal_3 = nn.Sequential(nn.Conv3d(40, 50, 3),\n",
    "                                             nn.Conv3d(50, 50, 3))\n",
    "        self.res_low_1 = nn.Sequential(nn.Conv3d(4, 30, 3), \n",
    "                                             nn.Conv3d(30, 30, 3), \n",
    "                                             nn.Conv3d(30, 40, 3),\n",
    "                                             nn.Conv3d(40, 40, 3))\n",
    "        self.res_low_2 = nn.Sequential(nn.Conv3d(40, 40, 3),\n",
    "                                             nn.Conv3d(40, 40, 3))\n",
    "        self.res_low_3 = nn.Sequential(nn.Conv3d(40, 50, 3),\n",
    "                                             nn.Conv3d(50, 50, 3))\n",
    "        self.fc_path = nn.Sequential(nn.Linear(100 * 9 * 9 * 9, 150 * 9 * 9 * 9),\n",
    "                                     nn.Linear(150 * 9 * 9 * 9, 150 * 9 * 9 * 9),\n",
    "                                     nn.Linear(150 * 9 * 9 * 9, 1 * 9 * 9 * 9))\n",
    "    def forward(self, x, y, alpha):\n",
    "        \n",
    "        mm = nn.Upsample(scale_factor = 2, mode='nearest')\n",
    "        N = x.size(0)\n",
    "        x_normal_1 = self.res_normal_1(x)\n",
    "        x_normal_c1 = x_normal_1[40, :9, :9, :9]\n",
    "        x_normal_2 = self.res_normal_2(x_normal_1)\n",
    "        x_normal_c2 = x_normal_2[40, :9, :9, :9]\n",
    "        x_normal_3 = self.res_normal_3(x_normal_2)\n",
    "        m = nn.Upsample(scale_factor = 3, mode='nearest')\n",
    "        x_low_1 = self.res_low_1(y)\n",
    "        x_low_up_1 = mm(x_low_1)\n",
    "        x_low_c1 = x_low_up_1[40, :9, :9, :9]\n",
    "        x_low_2 = self.res_low_2(x_low_1)\n",
    "        x_low_up_2 = mm(x_low_2)\n",
    "        x_low_c2 = x_low_up_2[40, :9, :9, :9]\n",
    "        x_low_3 = self.res_low_3(x_low_2)\n",
    "        x_low_c3 = m(x_low_3)\n",
    "        \n",
    "        concat = torch.cat(x_low_c1, x_low_c2, x_low_c3, x_normal_c1, x_normal_c2, x_normal_3)\n",
    "        \n",
    "        x_low = m(x_low_3)  \n",
    "        x_low_c3 = x_low_3\n",
    "        conc = torch.cat(x_normal_3, x_low)\n",
    "        N = conc.size(0) \n",
    "        out = out.view(N, -1)       \n",
    "        out = self.fc_path(out)\n",
    "        out = out.view(N, 1, 9, 9, 9)\n",
    "            \n",
    "        return out, concat\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Conv3d(410, 100, 3),\n",
    "        nn.Conv3d(100, 100, 3),\n",
    "        nn.Conv3d(100, 100, 3),\n",
    "        nn.Conv3d(100, 100, 3),\n",
    "        nn.Conv3d(100, 1, 1)\n",
    "        \n",
    "    )\n",
    "    return model\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(h_real, h_fake):\n",
    "   \n",
    "    \n",
    "    loss = -np.sum(np.log(h_real)) - np.sum(np.log(1 - h_fake))\n",
    "    loss /= np.prod(np.prod(h_real.shape))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmenter_loss(y_predict, y_true, alpha, h_real, h_fake, alpha):\n",
    "    \n",
    "    Z = - y_true * np.log(y_predict) - (1 - y_true) * np.log(1 - y_predict)\n",
    "    loss1 = np.sum(Z)\n",
    "    loss1 /= np.prod(Z.shape) \n",
    "    loss2 = -np.sum(np.log(h_real)) - np.sum(np.log(1 - h_fake))\n",
    "    loss2 /= np.prod(h_real.shape)\n",
    "    loss = loss1 - alpha * loss2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "   \n",
    "    optimizer = None\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_a_gan(D, S, D_solver, S_solver, discriminator_loss, segmenter_loss, show_every=250, \n",
    "              batch_size=128, num_epochs=50):\n",
    "\n",
    "    iter_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for x, y, x_s, x_t in loader_train:\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            x_high = \n",
    "            x_s_high = \n",
    "            x_t_high = \n",
    "            D_solver.zero_grad()\n",
    "            real_data = Variable(x).type(dtype)\n",
    "            \n",
    "            y_predict,  _ = S(x_high, x)\n",
    "            _, out_real = S(x_s_high, x_s)\n",
    "            _, out_fake = S(x_t_high, x_t)\n",
    "            h_real = D(out_real)\n",
    "            h_fake = D(out_fake)\n",
    "            D_error = discriminator_loss(h_real, h_fake)\n",
    "            D_error.backward()\n",
    "            D_solver.step()\n",
    "            \n",
    "            h_real = D(out_real)\n",
    "            h_fake = D(out_fake)\n",
    "            S_solver.zero_grad()\n",
    "            if epoch < 10:\n",
    "                \n",
    "                S_error = segmenter_loss(y_predict, y_true, alpha, h_real, h_fake, 0)\n",
    "                S_error.backward()\n",
    "                S_solver.step()\n",
    "            else if epoch < 35:\n",
    "                S_error = segmenter_loss(y_predict, y_true, alpha, h_real, h_fake, 0.05 * (epoch - 9) / (34 - 9))\n",
    "                S_error.backward()\n",
    "                S_solver.step()\n",
    "            else:\n",
    "                S_error = segmenter_loss(y_predict, y_true, alpha, h_real, h_fake, 0.05)\n",
    "                S_error.backward()\n",
    "                S_solver.step()\n",
    "            \n",
    "            if (iter_count % show_every == 0):\n",
    "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count, D_error.data[0], G_error.data[0]))\n",
    "               \n",
    "            iter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_images(images):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "    \n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
